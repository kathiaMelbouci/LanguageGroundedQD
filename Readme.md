
# Language Grounded Decision Transformers for QD-RL

This repo reproduces the results of the paper 

```
bibinfo goes here
```

**Note 1:** This repository requires `python3.8+` and `pytorch<2.0`. The results in the paper were produced with pytorch `1.11.0+cu113`. 
**Note 2:** The transformer in this repo was implemented by extending the nanoGPT (https://github.com/karpathy/nanoGPT) language model.

## Training the model

The policy repertoire used in the paper can be downloaded from <https://huggingface.co/datasets/Achkan/ToyEnvironmentDescribedPolicyRepertoire>.

Once you have the dataset, run

```
TBD
```

## Generating datasets

### Toy environment dependencies

1. Libfastsim (<https://github.com/sferes2/libfastsim>)
2. pyfastsim  (<https://github.com/mirandablue/pyfastsim>)
3. fastsim_gym (<https://github.com/mirandablue/fastsim_gym>)

### Dataset annotation dependencies

You need to add your openAI API key to the script `get_trajectory_description.py` (`openai.api_key="ADD YOUR KEY HERE"`).

## Generating datasets 

Run the following commands, using the archive generated at each step as input to the next:
```
python3 dataset_tools.py --generate_archive --out_dir <some_path> 
python3 dataset_tools.py --input_archive <generated_archive> --annotate_archive --out_dir <some_path/annotated_archive>
python3 dataset_tools.py --fix_duplicates
python3 dataset_tools.py --export_annotations --out_dir <annotations_dir>
```

Now use the `get_trajectory_description` with your `openai.api_key` to generate descriptions for the annotations that have been written to `annotations_dir`:

```
python3 get_trajectory_description <annotations_dir> <descriptions_dir>
```

Finally, add the llm generated descriptions to the archive:

```
python3 dataset_tools.py --input_archive <some_path/annotated_archive> --add_llm_descriptions <path_to_descriptions> --out_dir <some_path/described_archive>
```

A number of arguments such as `--visualize_llm_description_and_behavior` and `--verify_repeatability` can be used to inspect the generated archive.

You can now use the generated archive to train the model as specified above.

# Copyright notes

1. The images used in the toy environment to indicate household objects are vector images under creative commons licence, downloaded from openclipart.org.
2. The dataset contains text generated by `davinci-text-003`. According to openai's terms of use,

```quote
a) Your Content. You may provide input to the Services (“Input”), and receive output generated and returned by the Services based on the Input (“Output”). Input and Output are collectively “Content.” As between the parties and to the extent permitted by applicable law, you own all Input. Subject to your compliance with these Terms, OpenAI hereby assigns to you all its right, title and interest in and to Output. This means you can use Content for any purpose, including commercial purposes such as sale or publication, if you comply with these Terms. OpenAI may use Content to provide and maintain the Services, comply with applicable law, and enforce our policies. You are responsible for Content, including for ensuring that it does not violate any applicable law or these Terms.
```
so the generated dataset is released under afl-3.0.

3. Our code is licenced under GNU GPL V3: see the LICENCE file.
